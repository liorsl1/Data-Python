{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitf9c737f0009949478545e80807e14f50",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data class\n",
    "import random\n",
    "class Sentiment: #enum class for describing the score\n",
    "\n",
    "    NEGATIVE=\"NEGATIVE\"\n",
    "    NEUTRAL=\"NEUTRAL\"\n",
    "    POSITIVE=\"POSITIVE\"\n",
    "class Review:\n",
    "    def __init__(self,text,score):\n",
    "        self.text=text\n",
    "        self.score=score\n",
    "        self.sentiment=self.get_sentiment()\n",
    "\n",
    "    def get_sentiment(self):\n",
    "        if self.score<=2:\n",
    "            return Sentiment.NEGATIVE\n",
    "        elif self.score==3:\n",
    "            return Sentiment.NEUTRAL\n",
    "        else: #score of 4 or 5\n",
    "            return Sentiment.POSITIVE\n",
    "class ReviewContainer:\n",
    "    def __init__(self,reviews):\n",
    "        self.reviews=reviews\n",
    "    \n",
    "    def get_text(self):\n",
    "        return [x.text for x in self.reviews]   #x is the input of the text to the training, doing list comprehension to get only the elements we need in a list.\n",
    "\n",
    "    def get_sentiment(self):\n",
    "        return [x.sentiment for x in self.reviews]  #the input of the score to the training module.\n",
    "\n",
    "    def evenly_distribute(self): #filters the reviews and creates a balance between number of positive and negative(same number)\n",
    "        negative=list(filter(lambda x: x.sentiment==Sentiment.NEGATIVE,self.reviews))\n",
    "        positive=list(filter(lambda x: x.sentiment==Sentiment.POSITIVE,self.reviews))\n",
    "        positive_shrink=positive[:len(negative)]\n",
    "        self.reviews=negative + positive_shrink\n",
    "        random.shuffle(self.reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'NEUTRAL'"
     },
     "metadata": {},
     "execution_count": 260
    }
   ],
   "source": [
    "#Load data\n",
    "import json\n",
    "file_name='./data/Books_small_10000.json'\n",
    "reviews_list=[]\n",
    "with open(file_name) as f: #with works like a scope where the code runs only there. (like inditation or brackets)\n",
    "    for line in f:\n",
    "        dict_data=json.loads(line) #loads text in json style into a json dic\n",
    "        reviews_list.append(Review(dict_data['reviewText'],dict_data['overall'])) #create each element as Review class\n",
    "        #append inserts data to a list, here we insert a tuple of two                 elements(the text and score).\n",
    "reviews_list[1].sentiment\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "436"
     },
     "metadata": {},
     "execution_count": 261
    }
   ],
   "source": [
    "#Prep data\n",
    "from sklearn.model_selection import train_test_split\n",
    "training, test= train_test_split(reviews_list,test_size=0.33,random_state=42)\n",
    "train_container=ReviewContainer(training)\n",
    "test_container=ReviewContainer(test)\n",
    "train_container.evenly_distribute()\n",
    "test_container.evenly_distribute()\n",
    "train_x = train_container.get_text() \n",
    "train_y = train_container.get_sentiment()\n",
    "test_x=test_container.get_text()\n",
    "test_y=test_container.get_sentiment()\n",
    "train_y.count(Sentiment.POSITIVE)\n",
    "train_y.count(Sentiment.NEGATIVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer=CountVectorizer()\n",
    "train_x_vectors=vectorizer.fit_transform(train_x)\n",
    "test_x_vectors=vectorizer.transform(test_x)\n",
    "# print(test_y[3])\n",
    "# print(train_x_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To declare a class and use it, the declation needs to be above the program ofc, otherwise we wont have the definition.(which is why Review class is above)\n",
    "Basically, it makes the code more neat and clean using classes instead of indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['POSITIVE'], dtype='<U8')"
     },
     "metadata": {},
     "execution_count": 263
    }
   ],
   "source": [
    "#Classification-> Linear SVM\n",
    "from sklearn import svm\n",
    "clf_svm=svm.SVC(kernel='linear')\n",
    "clf_svm.fit(train_x_vectors,train_y)\n",
    "test_x[0]\n",
    "clf_svm.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['POSITIVE'], dtype='<U8')"
     },
     "metadata": {},
     "execution_count": 264
    }
   ],
   "source": [
    "#Classification-> Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dec=DecisionTreeClassifier()\n",
    "clf_dec.fit(train_x_vectors,train_y)\n",
    "clf_dec.predict(test_x_vectors[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['POSITIVE'], dtype='<U8')"
     },
     "metadata": {},
     "execution_count": 265
    }
   ],
   "source": [
    "#Classification-> Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf_gnb=GaussianNB()\n",
    "clf_gnb.fit(train_x_vectors.toarray(),train_y)\n",
    "clf_gnb.predict(test_x_vectors[3].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.7980769230769231\n0.6274038461538461\n0.6346153846153846\n"
    }
   ],
   "source": [
    "#Evaluation\n",
    "#Mean Accuracy\n",
    "print(clf_svm.score(test_x_vectors,test_y))\n",
    "print(clf_dec.score(test_x_vectors,test_y))\n",
    "print(clf_gnb.score(test_x_vectors.toarray(),test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0.8028169 , 0.        , 0.79310345])"
     },
     "metadata": {},
     "execution_count": 267
    }
   ],
   "source": [
    "#F1 Scores\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(test_y,clf_svm.predict(test_x_vectors),average=None,labels=[Sentiment.POSITIVE,Sentiment.NEUTRAL,Sentiment.NEGATIVE])\n",
    "\n",
    "#We got 91% for positive review, but shitty 20% for neutral and negative.\n",
    "#----\n",
    "#after the twiching to data that we did, with evenly contributing and getting larger chunk of data, we got a 80% for positive and 0.79% for negative, quite nice in equality terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['POSITIVE' 'NEGATIVE' 'NEGATIVE' 'POSITIVE' 'NEGATIVE']\n"
    }
   ],
   "source": [
    "#Testing the ML model\n",
    "test_set=['I thouroughly enjoyed this,5 stars'\n",
    ",'bad book do not buy',\n",
    "'horrible waste of time',\n",
    "'The best thing ive ever seen.',\n",
    "'0/10 weebs everywhere']\n",
    "new_test=vectorizer.transform(test_set)\n",
    "print(clf_svm.predict(new_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "208"
     },
     "metadata": {},
     "execution_count": 269
    }
   ],
   "source": [
    "test_y.count(Sentiment.POSITIVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuning our model (with Grid Search)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# tuned_svm="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#vectorizer.fit_transfrom explanation:\n",
    "\n",
    "vectorizer.get_feature_names() == (\n",
    "...     ['and', 'document', 'first', 'is', 'one',\n",
    "...      'second', 'the', 'third', 'this'])\n",
    "True\n",
    "\n",
    ">>> X.toarray()\n",
    "array([[0, 1, 1, 1, 0, 0, 1, 0, 1],\n",
    "       [0, 1, 0, 1, 0, 2, 1, 0, 1],\n",
    "       [1, 0, 0, 0, 1, 0, 1, 1, 0],\n",
    "       [0, 1, 1, 1, 0, 0, 1, 0, 1]]...)\n",
    "       for every row in the matrix is a representation of the list we have\n",
    "       above in get_feature_names(), and every digit in the corresponding\n",
    "       place defines how many times that words show up in our corresponding\n",
    "       row of matrix as the row of the string in our original tested list.\n",
    "#another one:\n",
    ".transform(X) = Transform dictionary features into 2D feature matrix.\n",
    ".fit_transform(X) = learn feature names + .transform(X)\n",
    "To answer your question:\n",
    "\n",
    "You can .transform only after learning the features using .fit. Directly applying .transform will ignore any features not encoutered in .fit and hence, would not output any classification results.\n"
   ]
  }
 ]
}